{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c881f145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from rl_glue import RLGlue\n",
    "\n",
    "from environment import BaseEnvironment\n",
    "from car_racing import CarRacingEnvironment\n",
    "from agent import BaseAgent \n",
    "\n",
    "from collections import deque\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import os \n",
    "import shutil\n",
    "from plot_script import plot_result\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5ddb28",
   "metadata": {},
   "source": [
    "## Neural Network for action values\n",
    "\n",
    "We use a neural network with one hidden layer for approximating the action-value function in a control problem. The output layer size is the number of actions. \n",
    "\n",
    "The get_action_values() function computes the action-value function by doing a forward pass.\n",
    "The get_TD_update() function computes the gradient of the action-value function with respect to the weights times the TD error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42e83475",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionValueNetwork:\n",
    "\n",
    "    def __init__(self, network_config):\n",
    "        self.state_dim = network_config.get(\"state_dim\")\n",
    "        self.num_actions = network_config.get(\"num_actions\")\n",
    "        self.learning_rate = network_config.get(\"learning_rate\")\n",
    "\n",
    "#         inputs = layers.Input(shape=(self.state_dim, self.state_dim, 3))\n",
    "#         # Convolutions on the frames on the screen\n",
    "#         layer1 = layers.Conv2D(6, 7, strides=4, activation=\"relu\")(inputs)\n",
    "#         layer2 = layers.MaxPooling2D(pool_size = (2,2))(layer1)\n",
    "#         layer3 = layers.Conv2D(12, 4, strides=2, activation=\"relu\")(layer2)\n",
    "#         layer4 = layers.MaxPooling2D(pool_size = (2,2))(layer3)\n",
    "#         layer5 = layers.Flatten()(layer4)\n",
    "#         layer6 = layers.Dense(512, activation=\"relu\")(layer5)\n",
    "#         action = layers.Dense(self.num_actions, activation=\"linear\")(layer6)\n",
    "\n",
    "#         self.model =  keras.Model(inputs=inputs, outputs=action)\n",
    "        \n",
    "        model = Sequential()\n",
    "#         model.add(layers.Input(shape=(self.state_dim, self.state_dim, 3)))\n",
    "        model.add(layers.Conv2D(filters = 6, kernel_size = 7, strides=3, activation=\"relu\", input_shape = (self.state_dim, self.state_dim, 3)))\n",
    "        \n",
    "        model.add(layers.MaxPooling2D(pool_size = (2,2)))\n",
    "        model.add(layers.Conv2D(filters = 12, kernel_size = 4, activation=\"relu\"))\n",
    "        model.add(layers.MaxPooling2D(pool_size = (2,2)))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(216, activation=\"relu\"))\n",
    "        model.add(layers.Dense(self.num_actions, activation=None))\n",
    "        model.compile(loss = 'mean_squared_error', optimizer=Adam(lr=self.learning_rate, epsilon=1e-7))\n",
    "        self.model = model\n",
    "#         model = models.Sequential()\n",
    "#         model.add(layers.Conv2D(32, 8, strides = 4, activation='relu', input_shape=(32, 32, 3)))\n",
    "#         model.add(layers.MaxPooling2D((2, 2)))\n",
    "#         model.add(layers.Conv2D(64, 4, strides = 2, activation='relu'))\n",
    "#         model.add(layers.MaxPooling2D((2, 2)))\n",
    "#         model.add(layers.Conv2D(64, 3, activation='relu'))\n",
    "#         model.add(layers.Flatten())\n",
    "#         model.add(layers.Dense(512, activation=\"relu\")(layer4))\n",
    "#         model.add(layers.Dense(self.num_actions, activation=\"linear\"))\n",
    "        \n",
    "#         self.model = model\n",
    "\n",
    "    def get_action_values(self, s):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            s (Numpy array): The state.\n",
    "        Returns:\n",
    "            The action-values (Numpy array) calculated using the network's weights.\n",
    "        \"\"\"\n",
    "        \n",
    "        q_vals = self.model.predict(s)\n",
    "\n",
    "        return q_vals\n",
    "    \n",
    "\n",
    "#     def get_TD_update(self, s, delta_mat):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             s (Numpy array): The state.\n",
    "#             delta_mat (Numpy array): A 2D array of shape (batch_size, num_actions). Each row of delta_mat  \n",
    "#             correspond to one state in the batch. Each row has only one non-zero element \n",
    "#             which is the TD-error corresponding to the action taken.\n",
    "#         Returns:\n",
    "#             The TD update (Array of dictionaries with gradient times TD errors) for the network's weights\n",
    "#         \"\"\"\n",
    "\n",
    "#         W0, b0 = self.weights[0]['W'], self.weights[0]['b']\n",
    "#         W1, b1 = self.weights[1]['W'], self.weights[1]['b']\n",
    "        \n",
    "#         psi = np.dot(s, W0) + b0\n",
    "#         x = np.maximum(psi, 0)\n",
    "#         dx = (psi > 0).astype(float)\n",
    "\n",
    "#         # td_update has the same structure as self.weights, that is an array of dictionaries.\n",
    "#         # td_update[0][\"W\"], td_update[0][\"b\"], td_update[1][\"W\"], and td_update[1][\"b\"] have the same shape as \n",
    "#         # self.weights[0][\"W\"], self.weights[0][\"b\"], self.weights[1][\"W\"], and self.weights[1][\"b\"] respectively\n",
    "#         td_update = [dict() for i in range(len(self.weights))]\n",
    "         \n",
    "#         v = delta_mat\n",
    "#         td_update[1]['W'] = np.dot(x.T, v) * 1. / s.shape[0]\n",
    "#         td_update[1]['b'] = np.sum(v, axis=0, keepdims=True) * 1. / s.shape[0]\n",
    "        \n",
    "#         v = np.dot(v, W1.T) * dx\n",
    "#         td_update[0]['W'] = np.dot(s.T, v) * 1. / s.shape[0]\n",
    "#         td_update[0]['b'] = np.sum(v, axis=0, keepdims=True) * 1. / s.shape[0]\n",
    "                \n",
    "#         return td_update\n",
    "        \n",
    "    \n",
    "    def get_weights(self):\n",
    "        return self.model.get_weights()\n",
    "    \n",
    "    def set_weights(self, weights):\n",
    "        self.model.set_weights(weights)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db59e3e5",
   "metadata": {},
   "source": [
    "## Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1447670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, size, minibatch_size, seed):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            size (integer): The size of the replay buffer.              \n",
    "            minibatch_size (integer): The sample size.\n",
    "            seed (integer): The seed for the random number generator. \n",
    "        \"\"\"\n",
    "        self.buffer = []\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.rand_generator = np.random.RandomState(seed)\n",
    "        self.max_size = size\n",
    "\n",
    "    def append(self, state, action, reward, terminal, next_state):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            state (Numpy array): The state.              \n",
    "            action (integer): The action.\n",
    "            reward (float): The reward.\n",
    "            terminal (integer): 1 if the next state is a terminal state and 0 otherwise.\n",
    "            next_state (Numpy array): The next state.           \n",
    "        \"\"\"\n",
    "        if len(self.buffer) == self.max_size:\n",
    "            del self.buffer[0]\n",
    "        state = state.astype('float32')\n",
    "        next_state = next_state.astype('float32')\n",
    "        self.buffer.append([state, action, reward, terminal, next_state])\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            A list of transition tuples including state, action, reward, terinal, and next_state\n",
    "        \"\"\"\n",
    "        idxs = self.rand_generator.choice(np.arange(len(self.buffer)), size=self.minibatch_size)\n",
    "        return [self.buffer[idx] for idx in idxs]\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25a8337",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb87db71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(action_values, tau=1.0):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        action_values (Numpy array): A 2D array of shape (batch_size, num_actions). \n",
    "                       The action-values computed by an action-value network.              \n",
    "        tau (float): The temperature parameter scalar.\n",
    "    Returns:\n",
    "        A 2D array of shape (batch_size, num_actions). Where each column is a probability distribution over\n",
    "        the actions representing the policy.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute the preferences by dividing the action-values by the temperature parameter tau\n",
    "    preferences = action_values/tau\n",
    "    # Compute the maximum preference across the actions\n",
    "    max_preference = np.max(preferences, axis=1)\n",
    "        \n",
    "    \n",
    "    # Reshape max_preference array which has shape [Batch,] to [Batch, 1]. This allows NumPy broadcasting \n",
    "    # when subtracting the maximum preference from the preference of each action.\n",
    "    reshaped_max_preference = max_preference.reshape((-1, 1))\n",
    "    \n",
    "    # Compute the numerator, i.e., the exponential of the preference - the max preference.\n",
    "    exp_preferences = np.exp(preferences - reshaped_max_preference)\n",
    "    # Compute the denominator, i.e., the sum over the numerator along the actions axis.\n",
    "    sum_of_exp_preferences = np.sum(exp_preferences, axis=1)\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Reshape sum_of_exp_preferences array which has shape [Batch,] to [Batch, 1] to  allow for NumPy broadcasting \n",
    "    # when dividing the numerator by the denominator.\n",
    "    reshaped_sum_of_exp_preferences = sum_of_exp_preferences.reshape((-1, 1))\n",
    "    \n",
    "    # Compute the action probabilities according to the equation in the previous cell.\n",
    "    action_probs = exp_preferences/reshaped_sum_of_exp_preferences\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    # squeeze() removes any singleton dimensions. It is used here because this function is used in the \n",
    "    # agent policy when selecting an action (for which the batch dimension is 1.) As np.random.choice is used in \n",
    "    # the agent policy and it expects 1D arrays, we need to remove this singleton batch dimension.\n",
    "    action_probs = action_probs.squeeze()\n",
    "    return action_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0635bd91",
   "metadata": {},
   "source": [
    "## Compiling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a50cccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_td_error(states, next_states, actions, rewards, discount, terminals, network, current_q, tau):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        states (Numpy array): The batch of states with the shape (batch_size, state_dim).\n",
    "        next_states (Numpy array): The batch of next states with the shape (batch_size, state_dim).\n",
    "        actions (Numpy array): The batch of actions with the shape (batch_size,).\n",
    "        rewards (Numpy array): The batch of rewards with the shape (batch_size,).\n",
    "        discount (float): The discount factor.\n",
    "        terminals (Numpy array): The batch of terminals with the shape (batch_size,).\n",
    "        network (ActionValueNetwork): The latest state of the network that is getting replay updates.\n",
    "        current_q (ActionValueNetwork): The fixed network used for computing the targets, \n",
    "                                        and particularly, the action-values at the next-states.\n",
    "    Returns:\n",
    "        The TD errors (Numpy array) for actions taken, of shape (batch_size,)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Here network is the latest state of the network that is getting replay updates. In other words, \n",
    "    # the network represents Q_{t+1}^{i} whereas current_q represents Q_t, the fixed network used for computing the \n",
    "    # targets, and particularly, the action-values at the next-states.\n",
    "    \n",
    "    # Compute action values at next states using current_q network\n",
    "    # q_next_mat is a 2D array of shape (batch_size, num_actions)\n",
    "    \n",
    "    # Q(t+1)\n",
    "    q_next_mat = current_q.get_action_values(next_states)\n",
    " \n",
    "    # Compute policy at next state by passing the action-values in q_next_mat to softmax()\n",
    "    # probs_mat is a 2D array of shape (batch_size, num_actions)\n",
    "    \n",
    "    # Pi\n",
    "    probs_mat = softmax(q_next_mat, tau)\n",
    "\n",
    "    # Compute the estimate of the next state value, v_next_vec.\n",
    "    # v_next_vec is a 1D array of shape (batch_size,)\n",
    "\n",
    "    v_next_vec = np.sum(probs_mat * q_next_mat, axis=1) * (1-terminals)\n",
    "    \n",
    "    # Compute Expected Sarsa target\n",
    "    # target_vec is a 1D array of shape (batch_size,)\n",
    "    \n",
    "    # \n",
    "    target_vec = rewards + discount*v_next_vec\n",
    "\n",
    "    # Compute action values at the current states for all actions using network\n",
    "    # q_mat is a 2D array of shape (batch_size, num_actions)\n",
    "   \n",
    "    q_mat = network.get_action_values(states)\n",
    "\n",
    "    # Batch Indices is an array from 0 to the batch size - 1. \n",
    "    batch_indices = np.arange(q_mat.shape[0])\n",
    "\n",
    "    # Compute q_vec by selecting q(s, a) from q_mat for taken actions\n",
    "    # Use batch_indices as the index for the first dimension of q_mat\n",
    "    # q_vec is a 1D array of shape (batch_size)\n",
    "    \n",
    "#     q_vec = q_mat[batch_indices, int(actions)]\n",
    "\n",
    "    # Compute TD errors for actions taken\n",
    "    # delta_vec is a 1D array of shape (batch_size)\n",
    "    \n",
    "#     delta_vec = target_vec - q_vec\n",
    "    target = np.zeros(q_next_mat.shape)\n",
    "    for i in range(q_next_mat.shape[0]):\n",
    "        \n",
    "        target[i,int(actions[i])] = target_vec[i]\n",
    "        \n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43dcf7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_network(experiences, discount, optimizer, network, current_q, tau):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        experiences (Numpy array): The batch of experiences including the states, actions, \n",
    "                                   rewards, terminals, and next_states.\n",
    "        discount (float): The discount factor.\n",
    "        network (ActionValueNetwork): The latest state of the network that is getting replay updates.\n",
    "        current_q (ActionValueNetwork): The fixed network used for computing the targets, \n",
    "                                        and particularly, the action-values at the next-states.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get states, action, rewards, terminals, and next_states from experiences\n",
    "    states, actions, rewards, terminals, next_states = map(list, zip(*experiences))\n",
    "    states = np.concatenate(states)\n",
    "    next_states = np.concatenate(next_states)\n",
    "    rewards = np.array(rewards)\n",
    "    terminals = np.array(terminals)\n",
    "    batch_size = states.shape[0]\n",
    "    loss_function = keras.losses.Huber()\n",
    "    # Compute TD error using the get_td_error function\n",
    "    # q_vec is a 1D array of shape (batch_size)\n",
    "    target_vec = get_td_error(states, next_states, actions, rewards, discount, terminals, network, current_q, tau)\n",
    "    \n",
    "    network.model.fit(states, target_vec, epochs=1, verbose=0)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003c90e3",
   "metadata": {},
   "source": [
    "## Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60c28d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(BaseAgent):\n",
    "    def __init__(self):\n",
    "        self.name = \"expected_sarsa_agent\"\n",
    "        \n",
    "    def agent_init(self, agent_config):\n",
    "        \"\"\"Setup for the agent called when the experiment first starts.\n",
    "\n",
    "        Set parameters needed to setup the agent.\n",
    "\n",
    "        Assume agent_config dict contains:\n",
    "        {\n",
    "            network_config: dictionary,\n",
    "            optimizer_config: dictionary,\n",
    "            replay_buffer_size: integer,\n",
    "            minibatch_sz: integer, \n",
    "            num_replay_updates_per_step: float\n",
    "            discount_factor: float,\n",
    "        }\n",
    "        \"\"\"\n",
    "        self.replay_buffer = ReplayBuffer(agent_config['replay_buffer_size'], \n",
    "                                          agent_config['minibatch_sz'], agent_config.get(\"seed\"))\n",
    "        self.network = ActionValueNetwork(agent_config['network_config'])\n",
    "        self.network_target = ActionValueNetwork(agent_config['network_config'])\n",
    "        self.num_actions = agent_config['network_config']['num_actions']\n",
    "        self.num_replay = agent_config['num_replay_updates_per_step']\n",
    "        self.discount = agent_config['gamma']\n",
    "        self.tau = agent_config['tau']\n",
    "        \n",
    "        self.rand_generator = np.random.RandomState(agent_config.get(\"seed\"))\n",
    "        self.epsilon = 0.01\n",
    "        self.last_state = None\n",
    "        self.last_action = None\n",
    "        self.sum_rewards = 0\n",
    "        self.episode_steps = 0\n",
    "        self.optimizer = keras.optimizers.Adam(learning_rate=0.00025, clipnorm=1.0)\n",
    "        self.action_space = np.array([i for i in range(self.num_actions)])\n",
    "        self.action_space = self.action_space.astype('float32')\n",
    "        self.eps = 1\n",
    "        self.eps_min = 0.1\n",
    "        self.eps_decay = 0.999\n",
    "\n",
    "    def policy(self, state):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            state (Numpy array): the state.\n",
    "        Returns:\n",
    "            the action. \n",
    "        \"\"\"\n",
    "        if np.random.rand() > self.epsilon:\n",
    "            \n",
    "            action_values = self.network.get_action_values(state)\n",
    "            probs_batch = softmax(action_values, self.tau)\n",
    "            action = self.rand_generator.choice(self.num_actions, p=probs_batch.squeeze())\n",
    "        else:\n",
    "            action = np.random.choice(self.action_space)\n",
    "        return action\n",
    "\n",
    "    def agent_start(self, state):\n",
    "        \"\"\"The first method called when the experiment starts, called after\n",
    "        the environment starts.\n",
    "        Args:\n",
    "            state (Numpy array): the state from the\n",
    "                environment's evn_start function.\n",
    "        Returns:\n",
    "            The first action the agent takes.\n",
    "        \"\"\"\n",
    "        self.sum_rewards = 0\n",
    "        self.episode_steps = 0\n",
    "        self.last_state = np.array([state])\n",
    "        self.last_action = self.policy(self.last_state)\n",
    "        return self.last_action\n",
    "\n",
    "\n",
    "    def agent_step(self, reward, state):\n",
    "        \"\"\"A step taken by the agent.\n",
    "        Args:\n",
    "            reward (float): the reward received for taking the last action taken\n",
    "            state (Numpy array): the state from the\n",
    "                environment's step based, where the agent ended up after the\n",
    "                last step\n",
    "        Returns:\n",
    "            The action the agent is taking.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.sum_rewards += reward\n",
    "        self.episode_steps += 1\n",
    "        \n",
    "        # Make state an array of shape (1, state_dim) to add a batch dimension and\n",
    "        # to later match the get_action_values() and get_TD_update() functions\n",
    "        state = np.array([state])\n",
    "\n",
    "        # Select action\n",
    "        action = self.policy(state)\n",
    "        \n",
    "        # Append new experience to replay buffer\n",
    "        self.replay_buffer.append(self.last_state, self.last_action, reward, 0, state)\n",
    "        \n",
    "        # Perform replay steps:\n",
    "        if self.replay_buffer.size() > self.replay_buffer.minibatch_size:\n",
    "#             current_q = deepcopy(self.network)\n",
    "            self.network_target.set_weights(self.network.get_weights())\n",
    "            for _ in range(self.num_replay):\n",
    "                \n",
    "                # Get sample experiences from the replay buffer\n",
    "                experiences = self.replay_buffer.sample()\n",
    "                \n",
    "                # Call optimize_network to update the weights of the network \n",
    "                optimize_network(experiences, self.discount, self.optimizer, self.network, self.network_target, self.tau)\n",
    "                \n",
    "        # Update the last state and last action.\n",
    "        self.last_state = state\n",
    "        self.last_action = action\n",
    "        \n",
    "        if self.eps > self.eps_min:\n",
    "            self.eps *= self.eps_decay\n",
    "        \n",
    "        \n",
    "        return action\n",
    "\n",
    "    def agent_end(self, reward):\n",
    "        \"\"\"Run when the agent terminates.\n",
    "        Args:\n",
    "            reward (float): the reward the agent received for entering the\n",
    "                terminal state.\n",
    "        \"\"\"\n",
    "        self.sum_rewards += reward\n",
    "        self.episode_steps += 1\n",
    "        \n",
    "        # Set terminal state to an array of zeros\n",
    "        state = np.zeros_like(self.last_state)\n",
    "\n",
    "        # Append new experience to replay buffer       \n",
    "       \n",
    "        self.replay_buffer.append(self.last_state, self.last_action, reward, 1, state)\n",
    "        \n",
    "        # Perform replay steps:\n",
    "        if self.replay_buffer.size() > self.replay_buffer.minibatch_size:\n",
    "#             current_q = deepcopy(self.network)\n",
    "            self.network_target.set_weights(self.network.get_weights())\n",
    "            for _ in range(self.num_replay):\n",
    "                \n",
    "                # Get sample experiences from the replay buffer\n",
    "                experiences = self.replay_buffer.sample()\n",
    "                \n",
    "                # Call optimize_network to update the weights of the network\n",
    "                optimize_network(experiences, self.discount, self.optimizer, self.network, self.network_target, self.tau)\n",
    "                \n",
    "        \n",
    "    def trained_agent_step(self, reward, state):\n",
    "        \"\"\"A step taken by the trained agent.\n",
    "        Args:\n",
    "            reward (float): the reward received for taking the last action taken\n",
    "            state (Numpy array): the state from the\n",
    "                environment's step based, where the agent ended up after the\n",
    "                last step\n",
    "        Returns:\n",
    "            The action the agent is taking.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        self.sum_rewards += reward\n",
    "        # Make state an array of shape (1, state_dim) to add a batch dimension and\n",
    "        # to later match the get_action_values() and get_TD_update() functions\n",
    "        state = np.array([state])\n",
    "\n",
    "        # Select action\n",
    "        action = self.policy(state)\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    def agent_message(self, message):\n",
    "        if message == \"get_sum_reward\":\n",
    "            return self.sum_rewards\n",
    "        else:\n",
    "            raise Exception(\"Unrecognized Message!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbbbe316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights_to_json(model, file_name, path):\n",
    "    model_json = model.to_json()\n",
    "    file_name1 = ( str(file_name)+\".json\")\n",
    "    path = os.path.join(path, file_name1)\n",
    "    with open(path , \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model_json = model.to_json()\n",
    "    file_name2 = ( str(file_name)+\".h5\")\n",
    "    path = os.path.join(path, file_name2)\n",
    "    model.save_weights(path)\n",
    "    print(\"Saved model to disk\")\n",
    "    \n",
    "def loaf_weights_from_json(model, file_name, path):\n",
    "    file_name1 = ( str(file_name)+\".json\")\n",
    "    path = os.path.join(path, file_name1)\n",
    "    json_file = open(path, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    file_name2 = ( str(file_name)+\".h5\")\n",
    "    path = os.path.join(path, file_name2)\n",
    "    loaded_model.load_weights(path)\n",
    "    print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f250b0",
   "metadata": {},
   "source": [
    "## Run the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abe58618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kirat\\Anaconda3\\envs\\TensorGPU, Keras\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1143..1442 -> 299-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kirat\\Anaconda3\\envs\\TensorGPU, Keras\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] Cannot change thread mode after it is set\n",
      "  warnings.warn(str(err))\n",
      "  1%|▊                                                                             | 1/100 [06:45<11:09:38, 405.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1087..1369 -> 282-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▌                                                                            | 2/100 [13:32<11:04:00, 406.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 964..1212 -> 248-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1176..1474 -> 298-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▎                                                                           | 3/100 [20:21<10:58:33, 407.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1283..1608 -> 325-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███                                                                           | 4/100 [27:11<10:53:26, 408.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1217..1526 -> 309-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███▉                                                                          | 5/100 [34:00<10:46:52, 408.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1096..1374 -> 278-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▋                                                                         | 6/100 [40:50<10:40:50, 409.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1198..1501 -> 303-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▍                                                                        | 7/100 [47:39<10:34:28, 409.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1159..1453 -> 294-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▏                                                                       | 8/100 [54:30<10:28:26, 409.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 957..1205 -> 248-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|██████▊                                                                     | 9/100 [1:01:22<10:22:11, 410.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1181..1480 -> 299-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████▌                                                                   | 10/100 [1:08:14<10:16:19, 410.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 979..1234 -> 255-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████████▎                                                                  | 11/100 [1:15:06<10:10:13, 411.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1320..1654 -> 334-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████                                                                  | 12/100 [1:22:02<10:05:17, 412.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1067..1338 -> 271-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████████▊                                                                 | 13/100 [1:28:59<10:00:19, 414.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1067..1338 -> 271-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|██████████▋                                                                 | 14/100 [1:36:00<9:56:28, 416.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1207..1513 -> 306-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|███████████▍                                                                | 15/100 [1:42:58<9:50:20, 416.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1106..1396 -> 290-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▏                                                               | 16/100 [1:48:40<9:11:56, 394.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1296..1628 -> 332-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1047..1319 -> 272-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|████████████▉                                                               | 17/100 [1:51:20<7:27:56, 323.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1245..1560 -> 315-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█████████████▋                                                              | 18/100 [1:58:15<7:59:55, 351.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1232..1544 -> 312-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|██████████████▍                                                             | 19/100 [2:05:09<8:19:33, 370.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1120..1408 -> 288-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████▏                                                            | 20/100 [2:12:04<8:31:08, 383.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1225..1536 -> 311-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|███████████████▉                                                            | 21/100 [2:18:57<8:36:49, 392.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1077..1357 -> 280-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|████████████████▋                                                           | 22/100 [2:21:25<6:54:53, 319.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1322..1664 -> 342-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|█████████████████▍                                                          | 23/100 [2:28:20<7:26:20, 347.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1035..1297 -> 262-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██████████████████▏                                                         | 24/100 [2:33:12<6:59:24, 331.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1297..1626 -> 329-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|███████████████████                                                         | 25/100 [2:40:06<7:25:01, 356.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1294..1621 -> 327-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|███████████████████▊                                                        | 26/100 [2:47:00<7:40:20, 373.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1055..1331 -> 276-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|████████████████████▌                                                       | 27/100 [2:49:38<6:15:40, 308.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1202..1507 -> 305-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|█████████████████████▎                                                      | 28/100 [2:56:32<6:48:14, 340.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 863..1087 -> 224-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██████████████████████                                                      | 29/100 [2:58:56<5:33:03, 281.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1227..1538 -> 311-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██████████████████████▊                                                     | 30/100 [3:05:50<6:14:48, 321.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1317..1652 -> 335-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███████████████████████▌                                                    | 31/100 [3:12:44<6:41:23, 349.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1115..1402 -> 287-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|████████████████████████▎                                                   | 32/100 [3:15:00<5:22:56, 284.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1168..1464 -> 296-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|█████████████████████████                                                   | 33/100 [3:21:54<6:01:25, 323.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1056..1324 -> 268-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|█████████████████████████▊                                                  | 34/100 [3:28:48<6:26:08, 351.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1204..1509 -> 305-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|██████████████████████████▌                                                 | 35/100 [3:35:42<6:40:43, 369.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1260..1579 -> 319-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███████████████████████████▎                                                | 36/100 [3:42:37<6:48:46, 383.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1100..1379 -> 279-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|████████████████████████████                                                | 37/100 [3:49:31<6:52:16, 392.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1185..1485 -> 300-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|████████████████████████████▉                                               | 38/100 [3:56:25<6:52:16, 398.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1034..1296 -> 262-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|█████████████████████████████▋                                              | 39/100 [4:03:19<6:50:15, 403.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1076..1352 -> 276-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1132..1419 -> 287-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|██████████████████████████████▍                                             | 40/100 [4:10:13<6:46:42, 406.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1292..1619 -> 327-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|███████████████████████████████▏                                            | 41/100 [4:17:07<6:42:04, 408.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1275..1598 -> 323-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|███████████████████████████████▉                                            | 42/100 [4:24:01<6:36:46, 410.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1056..1324 -> 268-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████████████████████████████████▋                                           | 43/100 [4:30:55<6:30:51, 411.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1092..1377 -> 285-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|█████████████████████████████████▍                                          | 44/100 [4:37:48<6:24:32, 412.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1127..1413 -> 286-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|██████████████████████████████████▏                                         | 45/100 [4:44:42<6:18:03, 412.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1104..1384 -> 280-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|██████████████████████████████████▉                                         | 46/100 [4:51:36<6:11:31, 412.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1131..1430 -> 299-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1195..1498 -> 303-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|███████████████████████████████████▋                                        | 47/100 [4:58:30<6:05:02, 413.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1155..1448 -> 293-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████████████████████████████████████▍                                       | 48/100 [5:05:24<5:58:26, 413.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1317..1650 -> 333-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|█████████████████████████████████████▏                                      | 49/100 [5:12:18<5:51:43, 413.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1180..1479 -> 299-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████                                      | 50/100 [5:19:12<5:44:50, 413.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1170..1467 -> 297-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|██████████████████████████████████████▊                                     | 51/100 [5:26:07<5:38:10, 414.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1022..1282 -> 260-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|███████████████████████████████████████▌                                    | 52/100 [5:33:11<5:33:36, 417.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1230..1542 -> 312-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|████████████████████████████████████████▎                                   | 53/100 [5:40:05<5:25:55, 416.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1018..1278 -> 260-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1126..1412 -> 286-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████████████████████████████████████████                                   | 54/100 [5:46:59<5:18:34, 415.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1251..1568 -> 317-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████████████████████████████████████████▊                                  | 55/100 [5:53:53<5:11:20, 415.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1202..1507 -> 305-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|██████████████████████████████████████████▌                                 | 56/100 [6:00:47<5:04:13, 414.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1265..1592 -> 327-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|███████████████████████████████████████████▎                                | 57/100 [6:07:42<4:57:12, 414.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1049..1315 -> 266-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|████████████████████████████████████████████                                | 58/100 [6:14:36<4:50:07, 414.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1345..1685 -> 340-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|████████████████████████████████████████████▊                               | 59/100 [6:21:30<4:43:13, 414.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 929..1167 -> 238-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1059..1328 -> 269-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████▌                              | 60/100 [6:28:24<4:36:09, 414.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 981..1236 -> 255-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████████████████████████████████████████████▎                             | 61/100 [6:31:05<3:39:48, 338.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1220..1529 -> 309-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|███████████████████████████████████████████████                             | 62/100 [6:37:58<3:48:31, 360.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1062..1332 -> 270-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|███████████████████████████████████████████████▉                            | 63/100 [6:44:51<3:52:08, 376.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1148..1439 -> 291-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|████████████████████████████████████████████████▋                           | 64/100 [6:51:45<3:52:34, 387.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 983..1235 -> 252-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1106..1387 -> 281-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|█████████████████████████████████████████████████▍                          | 65/100 [6:58:38<3:50:34, 395.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1068..1339 -> 271-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████████████████████████████████████████████████▏                         | 66/100 [7:05:31<3:46:59, 400.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1285..1611 -> 326-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████████████████████████▉                         | 67/100 [7:12:25<3:42:31, 404.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1224..1534 -> 310-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|███████████████████████████████████████████████████▋                        | 68/100 [7:19:18<3:37:06, 407.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1095..1373 -> 278-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1209..1515 -> 306-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|████████████████████████████████████████████████████▍                       | 69/100 [7:26:12<3:31:21, 409.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1167..1463 -> 296-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████████▏                      | 70/100 [7:33:05<3:25:12, 410.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1215..1523 -> 308-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|█████████████████████████████████████████████████████▉                      | 71/100 [7:39:59<3:18:50, 411.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1292..1619 -> 327-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|██████████████████████████████████████████████████████▋                     | 72/100 [7:43:52<2:47:06, 358.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1099..1378 -> 279-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████████████████████████████████████████████████████▍                    | 73/100 [7:50:46<2:48:38, 374.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1179..1478 -> 299-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|████████████████████████████████████████████████████████▏                   | 74/100 [7:57:39<2:47:21, 386.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1107..1388 -> 281-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|█████████████████████████████████████████████████████████                   | 75/100 [8:04:33<2:44:25, 394.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1209..1519 -> 310-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1233..1544 -> 311-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1234..1555 -> 321-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|█████████████████████████████████████████████████████████▊                  | 76/100 [8:11:27<2:40:10, 400.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1232..1553 -> 321-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|██████████████████████████████████████████████████████████▌                 | 77/100 [8:19:05<2:40:02, 417.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1214..1522 -> 308-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████████████████████████████████████████████████████████▎                | 78/100 [8:26:57<2:39:09, 434.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1151..1450 -> 299-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|████████████████████████████████████████████████████████████                | 79/100 [8:30:05<2:06:04, 360.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1213..1529 -> 316-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████▊               | 80/100 [8:33:09<1:42:27, 307.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1252..1569 -> 317-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|█████████████████████████████████████████████████████████████▌              | 81/100 [8:40:37<1:50:41, 349.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1040..1304 -> 264-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|██████████████████████████████████████████████████████████████▎             | 82/100 [8:45:28<1:39:34, 331.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1128..1414 -> 286-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|███████████████████████████████████████████████████████████████             | 83/100 [8:52:44<1:42:55, 363.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1121..1408 -> 287-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1048..1319 -> 271-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|███████████████████████████████████████████████████████████████▊            | 84/100 [8:55:41<1:21:53, 307.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1224..1534 -> 310-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████████████████████████████████████████████████████████████▌           | 85/100 [9:03:55<1:30:50, 363.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1140..1429 -> 289-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|█████████████████████████████████████████████████████████████████▎          | 86/100 [9:12:14<1:34:16, 404.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1114..1400 -> 286-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1052..1319 -> 267-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|██████████████████████████████████████████████████████████████████          | 87/100 [9:20:56<1:35:13, 439.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1045..1313 -> 268-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1131..1418 -> 287-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████▉         | 88/100 [9:29:41<1:32:58, 464.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1122..1412 -> 290-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|███████████████████████████████████████████████████████████████████▋        | 89/100 [9:32:36<1:09:18, 378.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1239..1553 -> 314-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████████▍       | 90/100 [9:41:01<1:09:21, 416.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1022..1283 -> 261-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1123..1408 -> 285-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████████████████████████████████████████████████████████████████▏      | 91/100 [9:49:23<1:06:17, 441.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1158..1462 -> 304-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|███████████████████████████████████████████████████████████████████████▊      | 92/100 [9:52:10<47:54, 359.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1313..1645 -> 332-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|████████████████████████████████████████████████████████████████████████▌     | 93/100 [9:59:16<44:16, 379.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1000..1254 -> 254-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|████████████████████████████████████████████████████████████████████████▍    | 94/100 [10:06:35<39:42, 397.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1259..1578 -> 319-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████████████████████████████████████████████████████████████████████▏   | 95/100 [10:13:36<33:42, 404.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1316..1655 -> 339-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████████████████████████████████████████████████████████████████████▉   | 96/100 [10:16:09<21:55, 328.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1086..1367 -> 281-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|██████████████████████████████████████████████████████████████████████████▋  | 97/100 [10:18:29<13:36, 272.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 988..1238 -> 250-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|███████████████████████████████████████████████████████████████████████████▍ | 98/100 [10:25:23<10:29, 314.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1072..1344 -> 272-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|████████████████████████████████████████████████████████████████████████████▏| 99/100 [10:32:17<05:44, 344.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1152..1444 -> 292-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 100/100 [10:39:11<00:00, 383.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1066..1341 -> 275-tiles track\n",
      "Trained reward = [[nan]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def run_experiment(environment, agent, environment_parameters, agent_parameters, experiment_parameters):\n",
    "    \n",
    "    rl_glue = RLGlue(environment, agent)\n",
    "        \n",
    "    # save sum of reward at the end of each episode\n",
    "    agent_sum_reward = np.zeros((experiment_parameters[\"num_runs\"], \n",
    "                                 experiment_parameters[\"num_episodes\"]))\n",
    "    trained_agent_sum_reward = np.zeros((experiment_parameters[\"num_runs\"], \n",
    "                                 experiment_parameters[\"num_episodes_trained\"]))\n",
    "\n",
    "    env_info = {}\n",
    "\n",
    "    agent_info = agent_parameters\n",
    "\n",
    "    # one agent setting\n",
    "    for run in range(1, experiment_parameters[\"num_runs\"]+1):\n",
    "        agent_info[\"seed\"] = run\n",
    "        agent_info[\"network_config\"][\"seed\"] = run\n",
    "        env_info[\"seed\"] = run\n",
    "\n",
    "        rl_glue.rl_init(agent_info, env_info)\n",
    "\n",
    "            \n",
    "        for episode in tqdm(range(1, experiment_parameters[\"num_episodes\"]+1)):\n",
    "            # run episode\n",
    "            rl_glue.rl_episode(experiment_parameters[\"timeout\"])\n",
    "            \n",
    "            episode_reward = rl_glue.rl_agent_message(\"get_sum_reward\")\n",
    "            agent_sum_reward[run - 1, episode - 1] = episode_reward\n",
    "            \n",
    "        \n",
    "        for episode in range(1, experiment_parameters[\"num_episodes_trained\"]+1):\n",
    "            rl_glue.trained_rl_episode(experiment_parameters[\"timeout\"])\n",
    "            trained_agent_sum_reward[run - 1, episode - 1 ] =  rl_glue.rl_env_message(\"get_sum_reward\")\n",
    "            \n",
    "            print(\"Trained reward = \" + str(trained_agent_sum_reward))\n",
    "    save_name = \"{}\".format(rl_glue.agent.name)\n",
    "    if not os.path.exists('results'):\n",
    "        os.makedirs('results')\n",
    "    np.save(\"results/sum_reward_{}\".format(save_name), agent_sum_reward)\n",
    "    shutil.make_archive('results', 'zip', 'results')\n",
    "    \n",
    "    \n",
    "# Run Experiment\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "# Experiment parameters\n",
    "experiment_parameters = {\n",
    "    \"num_runs\" : 1,\n",
    "    \"num_episodes_trained\" : 1,\n",
    "    \"num_episodes\" : 100,\n",
    "    # OpenAI Gym environments allow for a timestep limit timeout, causing episodes to end after \n",
    "    # some number of timesteps. Here we use the default of 500.\n",
    "    \"timeout\" : 500\n",
    "}\n",
    "\n",
    "# Environment parameters\n",
    "environment_parameters = {}\n",
    "\n",
    "current_env = CarRacingEnvironment\n",
    "\n",
    "# Agent parameters\n",
    "agent_parameters = {\n",
    "    'network_config': {\n",
    "        'state_dim': 96,\n",
    "        'num_actions': 5,\n",
    "        'learning_rate':0.001\n",
    "    },\n",
    "    'replay_buffer_size': 5000,\n",
    "    'minibatch_sz': 8,\n",
    "    'num_replay_updates_per_step': 4,\n",
    "    'gamma': 0.99,\n",
    "    'tau': 0.001\n",
    "}\n",
    "current_agent = Agent\n",
    "\n",
    "# run experiment\n",
    "run_experiment(current_env, current_agent, environment_parameters, agent_parameters, experiment_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "604a3286",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './/sum_reward_random_agent.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-dc21af669f4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"expected_sarsa_agent\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"random_agent\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Github\\OpenAIGymReinfLearning\\OpenAIGym_CarRacing\\plot_script.py\u001b[0m in \u001b[0;36mplot_result\u001b[1;34m(data_name_array)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# load data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'sum_reward_{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0msum_reward_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}/{}.npy'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;31m# smooth data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TensorGPU, Keras\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './/sum_reward_random_agent.npy'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_result([\"expected_sarsa_agent\", \"random_agent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59fc1af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
